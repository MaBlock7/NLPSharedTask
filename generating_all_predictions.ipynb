{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T17:33:35.605633Z",
     "start_time": "2024-05-21T17:33:33.117958Z"
    }
   },
   "source": [
    "import torch, json, os\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:33:35.607876Z",
     "start_time": "2024-05-21T17:33:35.606447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_base = '/Volumes/SSK2tb/nlp'\n",
    "# all the models are ~10gbs"
   ],
   "id": "15cae16929f3867f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:33:10.930334Z",
     "start_time": "2024-05-21T19:33:10.913882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_models = ['muppet','scibert']\n",
    "finetuned_variants = [\n",
    "    'no_synth'\n",
    "    ,'llama'\n",
    "    ,'gpt-4'\n",
    "    ,'ensemble'\n",
    "    ,'mixtral'\n",
    "]\n",
    "models = [f\"{b}_{v}\" for b in base_models for v in finetuned_variants]\n",
    "# base = base_models[1]\n",
    "# fine = [finetuned_variants[2], finetuned_variants[3], finetuned_variants[4]]\n",
    "# models = [f\"{base}_{v}\" for v in fine]\n",
    "\n"
   ],
   "id": "da81c9b3ca60749a",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:33:13.685553Z",
     "start_time": "2024-05-21T19:33:13.612022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_file_path = 'testdata_results.jsonl'\n",
    "data = []\n",
    "with open(data_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))"
   ],
   "id": "dad2e6d35c8d42fa",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:33:18.771404Z",
     "start_time": "2024-05-21T19:33:18.766682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract abstracts and labels\n",
    "abstracts = [entry['ABSTRACT'] for entry in data]\n",
    "titles = [entry['TITLE'] for entry in data]\n",
    "true_labels = [entry['SDG'] for entry in data]"
   ],
   "id": "903deaa1d0234cca",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:33:25.690853Z",
     "start_time": "2024-05-21T19:33:25.677854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actual_data = pd.read_csv('/Users/andrew_yos/Downloads/PROCESSED_ZORA_TEST.csv')\n",
    "abstracts = actual_data['PROCESSED']\n",
    "# titles = [entry['TITLE'] for entry in data]\n",
    "true_labels = actual_data['SDG']"
   ],
   "id": "baa2c3af2f33dbd2",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:33:33.466456Z",
     "start_time": "2024-05-21T19:33:33.459402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from main_text_preprocessing import process_text\n",
    "def predict_using_model(model_path, conc=False):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    def classify_text(text):\n",
    "        # preprocess the text\n",
    "        # text = process_text(text)\n",
    "        \n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding='max_length')\n",
    "    \n",
    "        # Get the model predictions\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                outputs = model(**inputs)\n",
    "            except Exception as e:\n",
    "                print(f'Error for text {text}: {e}')\n",
    "                raise e\n",
    "                \n",
    "    \n",
    "        # Get the predicted class\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        return predictions.item()\n",
    "    \n",
    "    predicted_labels = [classify_text(a) for a in abstracts]\n",
    "    # if conc:\n",
    "    #     concatenated_texts = [title + \" \" + abstract for title, abstract in zip(titles, abstracts)]\n",
    "    #     predicted_labels = [classify_text(a) for a in concatenated_texts]\n",
    "    # else:\n",
    "    #     predicted_labels = [classify_text(a) for a in abstracts]\n",
    "     \n",
    "    return predicted_labels\n",
    "    "
   ],
   "id": "87263a2e106d31bd",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T19:43:56.287758Z",
     "start_time": "2024-05-21T19:33:53.052525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions_file_path = 'all_predictions_preprocessed_data.csv'\n",
    "def predict_all_and_save():\n",
    "    # Initialize a dictionary to hold predictions\n",
    "    all_predictions = {'truth': true_labels}\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"Predicting using model {model}\")\n",
    "        path = os.path.join(models_base, model)\n",
    "        predictions = predict_using_model(path, abstracts)\n",
    "        all_predictions[model] = predictions\n",
    "\n",
    "    # Create a DataFrame from the predictions dictionary\n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    # path = os.path.join(models_base, predictions_file_path)\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(predictions_file_path, index=False)\n",
    "predict_all_and_save()"
   ],
   "id": "fe306545e177685a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using model muppet_no_synth\n",
      "Predicting using model muppet_llama\n",
      "Predicting using model muppet_gpt-4\n",
      "Predicting using model muppet_ensemble\n",
      "Predicting using model muppet_mixtral\n",
      "Predicting using model scibert_no_synth\n",
      "Predicting using model scibert_llama\n",
      "Predicting using model scibert_gpt-4\n",
      "Predicting using model scibert_ensemble\n",
      "Predicting using model scibert_mixtral\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T18:05:50.042780Z",
     "start_time": "2024-05-21T18:05:50.019508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(df, variant):\n",
    "    # Extract true and predicted labels\n",
    "    y_true = df['truth']\n",
    "    y_pred = df[variant]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate macro metrics\n",
    "    macro_precision = precision_score(y_true, y_pred, average='macro')\n",
    "    macro_recall = recall_score(y_true, y_pred, average='macro')\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    weighted_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    weighted_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Create a dictionary to store the results\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_precision': macro_precision,\n",
    "        'macro_recall': macro_recall,\n",
    "        'macro_f1-score': macro_f1,\n",
    "        'weighted_precision': weighted_precision,\n",
    "        'weighted_recall': weighted_recall,\n",
    "        'weighted_f1-score': weighted_f1\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.DataFrame({'truth': [...], 'muppet_gpt-4': [...]})\n",
    "# metrics = calculate_metrics(df)\n",
    "# print(metrics)\n",
    "p = os.path.join(models_base, predictions_file_path)\n",
    "print(f\"reading {p}\")\n",
    "df = pd.read_csv(p)\n",
    "all_metrics = []\n",
    "for f in fine:\n",
    "    metrics = calculate_metrics(df, f'{base}_{f}')\n",
    "    all_metrics.append(metrics)\n",
    "    \n",
    "sep = '\\t\\t'\n",
    "\n",
    "headers = ['model_name'] + [str(m) for m in all_metrics[0].keys()]  \n",
    "\n",
    "print(sep.join(headers))\n",
    "for i,m in enumerate(all_metrics):\n",
    "    print(sep.join([fine[i]]+ [str(m[h]) for h in headers[1:]]))"
   ],
   "id": "1f5eabad5220363d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /Volumes/SSK2tb/nlp/predictions_preprocessedtext_submitted_models.csv\n",
      "model_name\t\taccuracy\t\tmacro_precision\t\tmacro_recall\t\tmacro_f1-score\t\tweighted_precision\t\tweighted_recall\t\tweighted_f1-score\n",
      "gpt-4\t\t0.47435897435897434\t\t0.4649462165236193\t\t0.5205488621151272\t\t0.4438127458960792\t\t0.6459375954607063\t\t0.47435897435897434\t\t0.5149256637237406\n",
      "ensemble\t\t0.44871794871794873\t\t0.41030121838945366\t\t0.5215751896474788\t\t0.41486932820266154\t\t0.6226075552150213\t\t0.44871794871794873\t\t0.48155492655492654\n",
      "mixtral\t\t0.5\t\t0.43493533215755437\t\t0.4919009370816599\t\t0.41268102712353216\t\t0.6413495455162123\t\t0.5\t\t0.5350638289387892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T17:52:44.148807Z",
     "start_time": "2024-05-21T17:52:44.145513Z"
    }
   },
   "cell_type": "code",
   "source": "all_metrics[1:]",
   "id": "c19d4789997d6a81",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.44871794871794873,\n",
       "  'macro_precision': 0.41030121838945366,\n",
       "  'macro_recall': 0.5215751896474788,\n",
       "  'macro_f1-score': 0.41486932820266154,\n",
       "  'weighted_precision': 0.6226075552150213,\n",
       "  'weighted_recall': 0.44871794871794873,\n",
       "  'weighted_f1-score': 0.48155492655492654},\n",
       " {'accuracy': 0.5,\n",
       "  'macro_precision': 0.43493533215755437,\n",
       "  'macro_recall': 0.4919009370816599,\n",
       "  'macro_f1-score': 0.41268102712353216,\n",
       "  'weighted_precision': 0.6413495455162123,\n",
       "  'weighted_recall': 0.5,\n",
       "  'weighted_f1-score': 0.5350638289387892}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac07738e300934ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
